{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Modeling_item_cd 최종.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mlcxtWEjUjwS","executionInfo":{"status":"ok","timestamp":1635356419146,"user_tz":-540,"elapsed":361,"user":{"displayName":"‍김연재(학부학생/공과대학 산업공학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14786412166966495024"}},"outputId":"65131c2d-cd76-4647-a5f8-20acff976fd1"},"source":["from google.colab import auth\n","auth.authenticate_user()\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X11eBgt8m_7G","executionInfo":{"status":"ok","timestamp":1635356447683,"user_tz":-540,"elapsed":28120,"user":{"displayName":"‍김연재(학부학생/공과대학 산업공학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14786412166966495024"}},"outputId":"23e7b57c-7f44-469d-eb95-28a63462dccb"},"source":["# download sktime package \n","!pip install sktime"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sktime\n","  Downloading sktime-0.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n","\u001b[K     |████████████████████████████████| 5.9 MB 7.7 MB/s \n","\u001b[?25hCollecting statsmodels>=0.12.1\n","  Downloading statsmodels-0.13.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n","\u001b[K     |████████████████████████████████| 9.8 MB 43.0 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.1.5)\n","Collecting scikit-learn>=0.24.0\n","  Downloading scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 64.8 MB/s \n","\u001b[?25hCollecting numba>=0.53\n","  Downloading numba-0.54.1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 34.7 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from sktime) (0.37.0)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.19.5)\n","Collecting llvmlite<0.38,>=0.37.0rc1\n","  Downloading llvmlite-0.37.0-cp37-cp37m-manylinux2014_x86_64.whl (26.3 MB)\n","\u001b[K     |████████████████████████████████| 26.3 MB 69 kB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.53->sktime) (57.4.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->sktime) (1.15.0)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (1.0.1)\n","Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.1->sktime) (0.5.2)\n","Installing collected packages: threadpoolctl, llvmlite, statsmodels, scikit-learn, numba, sktime\n","  Attempting uninstall: llvmlite\n","    Found existing installation: llvmlite 0.34.0\n","    Uninstalling llvmlite-0.34.0:\n","      Successfully uninstalled llvmlite-0.34.0\n","  Attempting uninstall: statsmodels\n","    Found existing installation: statsmodels 0.10.2\n","    Uninstalling statsmodels-0.10.2:\n","      Successfully uninstalled statsmodels-0.10.2\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","  Attempting uninstall: numba\n","    Found existing installation: numba 0.51.2\n","    Uninstalling numba-0.51.2:\n","      Successfully uninstalled numba-0.51.2\n","Successfully installed llvmlite-0.37.0 numba-0.54.1 scikit-learn-1.0.1 sktime-0.8.0 statsmodels-0.13.0 threadpoolctl-3.0.0\n"]}]},{"cell_type":"code","metadata":{"id":"aqS4t0ovUqTb"},"source":["# 필요한 패키지 import\n","import os\n","import sys\n","import warnings\n","import plotly\n","import numpy as np\n","import pandas as pd\n","import datetime\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold, train_test_split, TimeSeriesSplit, GridSearchCV, RandomizedSearchCV\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","from sklearn import preprocessing\n","from sklearn.preprocessing import RobustScaler, StandardScaler\n","import datetime\n","import tensorflow as tf\n","from tqdm import tqdm\n","from sktime.forecasting.model_selection import temporal_train_test_split\n","from sktime.utils.plotting import plot_series\n","from scipy.stats import reciprocal \n","\n","mpl.rcParams['figure.figsize'] = (8, 6)\n","mpl.rcParams['axes.grid'] = False\n","\n","warnings.filterwarnings('ignore')\n","pd.options.display.float_format = '{:.5f}'.format"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kHfb2sQ4mZe9"},"source":["from xgboost import XGBRegressor\n","from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n","from sklearn.svm import SVR\n","import lightgbm as lgb\n","from lightgbm.sklearn import LGBMRegressor\n","from sklearn.multioutput import MultiOutputRegressor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9ZVn4eEn9iq","executionInfo":{"status":"ok","timestamp":1635356451438,"user_tz":-540,"elapsed":318,"user":{"displayName":"‍김연재(학부학생/공과대학 산업공학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14786412166966495024"}},"outputId":"2b0b7147-4fc4-42e1-f1cf-ac2bb921a2e2"},"source":["%cd /content/gdrive/Shareddrives/cj공모전/traindata/시계열_item_cd/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/Shareddrives/cj공모전/traindata/시계열_item_cd\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CrMr06tdn_iE","executionInfo":{"status":"ok","timestamp":1635356452383,"user_tz":-540,"elapsed":952,"user":{"displayName":"‍김연재(학부학생/공과대학 산업공학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14786412166966495024"}},"outputId":"496258f7-dfdf-4f6e-8e3b-a807f2058bf1"},"source":["%ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["item_cd_138632647.pkl   item_cd_4802214590.pkl  item_cd_5326550997.pkl\n","item_cd_2055189125.pkl  item_cd_4824061918.pkl  item_cd_5404706313.pkl\n","item_cd_2108751155.pkl  item_cd_4904383364.pkl  item_cd_5480996007.pkl\n","item_cd_232155349.pkl   item_cd_4929712168.pkl  item_cd_5497354651.pkl\n","item_cd_3681859516.pkl  item_cd_4930635842.pkl  item_cd_5519470982.pkl\n","item_cd_414687646.pkl   item_cd_5002701828.pkl  item_cd_5521930034.pkl\n","item_cd_4207106945.pkl  item_cd_5002901812.pkl  item_cd_5534486731.pkl\n","item_cd_4288442391.pkl  item_cd_5102599276.pkl  item_cd_5569305322.pkl\n","item_cd_438888608.pkl   item_cd_5109058837.pkl  item_cd_5582257070.pkl\n","item_cd_447405954.pkl   item_cd_5121269742.pkl  item_cd_5636360821.pkl\n","item_cd_4609081354.pkl  item_cd_5157953843.pkl  item_cd_5638800672.pkl\n","item_cd_4610261043.pkl  item_cd_5187227890.pkl  item_cd_655045121.pkl\n","item_cd_4624200932.pkl  item_cd_5240328576.pkl  item_cd_657383604.pkl\n","item_cd_4658408144.pkl  item_cd_5240330199.pkl  item_cd_8809528221117.pkl\n","item_cd_4730793965.pkl  item_cd_5279251727.pkl  item_cd_8809528221414.pkl\n","item_cd_4733964360.pkl  item_cd_5279261934.pkl  item_cd_8809641652409.pkl\n","item_cd_4802177320.pkl  item_cd_5299553826.pkl\n"]}]},{"cell_type":"code","metadata":{"id":"6x6993ZHqvAf"},"source":["l0 = [ 5187227890, 655045121, 4624200932, 4610261043, 5326550997]\n","\n","l1 = [ 5299553826, 8809641652409, 5519470982, 8809528221117, 8809528221414]\n","\n","l2 = [ 4904383364, 4930635842, 5582257070, 5636360821, 5534486731]\n","\n","l3 =[ 3681859516, 4929712168, 2055189125, 4207106945, 5157953843]\n","\n","l4 =[ 2108751155, 5480996007, 5240328576, 5002901812, 5240330199]\n","\n","l5 =[ 232155349, 657383604, 5404706313, 414687646, 438888608]\n","\n","l6 = [ 5569305322, 138632647, 5102599276, 5121269742, 5521930034]\n","\n","l7 =[ 5638800672, 5002701828, 5497354651, 4730793965, 447405954]\n","\n","l8 =[ 4802177320, 4824061918, 4802214590, 4658408144, 4733964360]\n","\n","l9 =[ 4609081354, 5109058837, 4288442391, 5279261934, 5279251727]\n","\n","clusters = [l0, l1, l2, l3, l4, l5, l6, l7, l8, l9]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YXYZvSEhoFNQ"},"source":["# 학습에 필요한 train 및 test dataset 만드는 과정\n","def get_train_test_set(cd):\n","  df = pd.read_pickle(\"item_cd_\"+cd+\".pkl\")\n","  train = df[df['BKG_DATE'] <= '2021-06-20']\n","  test = df[df['BKG_DATE'] > '2021-06-20']\n","  # 나머지 Scaling\n","  scaling_features = ['요일', '휴일여부', 'DAY_1', 'DAY_2', 'DAY_3', 'week', 'WEEK_AMT', 'MEAN_PRICE',\n","       '강원', '경기', '경남', '경북', '광주', '대구', '대전', '부산', '서울', '세종', '울산', '인천',\n","       '전남', '전북', '제주', '충남', '충북']\n","  scaler = StandardScaler()\n","  train.loc[:, scaling_features] = scaler.fit_transform(train[scaling_features])\n","  test.loc[:, scaling_features] = scaler.transform(test[scaling_features])\n","  train_x = train.drop(['ITEM_QTY','BKG_DATE'], axis=1)\n","  train_y = train['ITEM_QTY']\n","\n","  test_x = test.drop(['ITEM_QTY','BKG_DATE'], axis=1)\n","  test_y = test['ITEM_QTY']\n","  return train_x, train_y, test_x, test_y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoKJha9-U3fw"},"source":["def get_stacking_base_datasets(model, x_train_n, y_train_n, x_test_n, n_splits=5):\n","  # 지정된 n_folds 값으로 KFold 생성\n","  tss = TimeSeriesSplit(n_splits)\n","\n","  # 추후 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화\n","  train_fold_pred=np.zeros((x_train_n.shape[0], 1))\n","  test_pred=np.zeros((x_test_n.shape[0], n_splits))\n","  #print(model.__class__.__name__, ' model 시작')\n","\n","  for folder_counter, (train_index, valid_index) in enumerate(tss.split(x_train_n)):\n","    # 입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 세트 추출\n","    #print('\\t 폴드 세트: ', folder_counter, ' 시작')\n","    x_tr=x_train_n[train_index]\n","    y_tr=y_train_n[train_index]\n","    x_te=x_train_n[valid_index]\n","\n","    # 폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행\n","    model.fit(x_tr, y_tr)\n","    # 폴드 세트 내부에서 다시 만들어지 검증 데이터로 기반 모델 예측 후 데이터 저장\n","    train_fold_pred[valid_index, :]=model.predict(x_te).reshape(-1, 1)\n","    # 입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장\n","    test_pred[:, folder_counter]=model.predict(x_test_n)\n","\n","  # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성\n","  test_pred_mean=np.mean(test_pred, axis=1).reshape(-1, 1)\n","\n","  # train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n","  return train_fold_pred, test_pred_mean"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fw_LCffCKoVE"},"source":["# 모델별 학습 파라미터 정의\n","XGBRegressor_param = {'n_estimators' : [100], 'eta' : [0.01], 'min_child_weight' : np.arange(1, 8, 1), 'max_depth' : np.arange(3,9,1) , 'colsample_bytree' :np.arange(0.8, 1.0, 0.1), 'subsample' :np.arange(0.8, 1.0, 0.1)}\n","LGBMRegressor_param = {'max_depth' : range(3,15,3), 'min_child_weight': range(1,6,2), 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100], 'learning_rate':[0.1, 0.01], 'max_depth' : [6,8,10]}\n","SVR_param = {'kernel':['linear'], 'C':[1.0], 'epsilon':[0.1]}\n","GradientBoostingRegressor_param = {'n_estimators':[100], 'max_depth':np.arange(3,20,3)}\n","AdaBoostRegressor_param = {'n_estimators' : np.arange(25, 100, 25), 'loss': ['linear', 'square', 'exponential'], 'learning_rate': np.arange(0.1, 1)} "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_YiraP3Lp5F"},"source":["# 모델별 정의\n","XGBRegressor_model = XGBRegressor(n_estimators = 100, objective = 'reg:squarederror')\n","LGBMRegressor_model = LGBMRegressor(n_estimators = 80)\n","SVR_model = SVR(kernel='linear', C=1.0, epsilon=0.1)\n","GradientBoostingRegressor_model = GradientBoostingRegressor(n_estimators=100, max_depth=3)\n","AdaBoostRegressor_model = AdaBoostRegressor(base_estimator=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xOwgwkfxOntj"},"source":["# 단일 모델별 최적 파라미터로 모델링\n","def print_best_params(model, params, x_train, x_test, y_train, y_test, log=False):\n","  tss = TimeSeriesSplit(n_splits=5)\n","  grid_model=GridSearchCV(model, cv = tss, param_grid=params, scoring='neg_mean_absolute_error')\n","  grid_model.fit(x_train, y_train)\n","  mae = -1 * grid_model.best_score_\n","\n","  best_model=grid_model.best_estimator_\n","  pred=best_model.predict(x_test)\n","\n","  if log:\n","    y_test=np.expm1(y_test)\n","    pred=np.expm1(pred)\n","  \n","  min_list = np.round(mean_absolute_error(y_test, pred), 4)\n","\n","  return best_model, min_list, pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r52YLUb9S20q"},"source":["\n","하나의 샘플이긴 하더라도<br>\n","\n","test MAE로 보았을 때<br>\n","XGBRegressor < GradientBoostingRegressor < SVR < AdaBoostRegressor < LGBMRegressor"]},{"cell_type":"code","metadata":{"id":"betSsoZEFiV3"},"source":["import sys\n","\n","mod = sys.modules[__name__]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"38oH54_i8r-B"},"source":["# 최적의 파라미터로 각각의 모델 학습\n","def get_optimal_model(cd):\n","  x_train, y_train, x_test, y_test = get_train_test_set(cd)\n","  x_train_n=x_train.values\n","  x_test_n=x_test.values\n","  y_train_n=y_train.values\n","  \n","  # 단일 모델별 성능 리스트\n","  single_list = dict()\n","\n","  # 단일 모델 학습\n","  globals()[\"XGBRegressor_model_tuned_{}\".format(cd)], single_list[\"XGBRegressor\"], globals()[\"single_pred_XGBRegressor_{}\".format(cd)] = print_best_params(XGBRegressor_model, XGBRegressor_param, x_train, x_test, y_train, y_test)\n","  globals()[\"LGBMRegressor_model_tuned_{}\".format(cd)], single_list[\"LGBMRegressor\"], globals()[\"single_pred_LGBMRegressor_{}\".format(cd)] = print_best_params(LGBMRegressor_model, LGBMRegressor_param, x_train, x_test, y_train, y_test)\n","  globals()[\"SVR_model_tuned_{}\".format(cd)], single_list[\"SVR\"], globals()[\"single_pred_SVR_{}\".format(cd)] = print_best_params(SVR_model, SVR_param, x_train, x_test, y_train, y_test)\n","  globals()[\"GradientBoostingRegressor_model_tuned_{}\".format(cd)], single_list[\"GradientBoostingRegressor\"], globals()[\"single_pred_GradientBoostingRegressor_{}\".format(cd)] = print_best_params(GradientBoostingRegressor_model, GradientBoostingRegressor_param, x_train, x_test, y_train, y_test)\n","  globals()[\"AdaBoostRegressor_model_tuned_{}\".format(cd)], single_list[\"AdaBoostRegressor\"], globals()[\"single_pred_AdaBoostRegressor_{}\".format(cd)] = print_best_params(AdaBoostRegressor_model, AdaBoostRegressor_param, x_train, x_test, y_train, y_test)\n","\n","  single_model_mae = sorted(single_list.items(), key = lambda item: item[1])\n","\n","  # Stacking 모델별 성능 리스트  \n","  stacking_list = dict()\n","\n","  # stacking model dataset 생성\n","  globals()[\"{}_train_{}\".format(single_model_mae[0][0], cd)], globals()[\"{}_test_{}\".format(single_model_mae[0][0], cd)] = get_stacking_base_datasets(getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[0][0], cd)), x_train_n, y_train_n, x_test_n, 5)                                                                                        \n","  globals()[\"{}_train_{}\".format(single_model_mae[1][0], cd)], globals()[\"{}_test_{}\".format(single_model_mae[1][0], cd)] = get_stacking_base_datasets(getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[1][0], cd)), x_train_n, y_train_n, x_test_n, 5) \n","                                                                                                            \n","  # 첫번째 경우\n","  stack_final_x_train = np.concatenate((getattr(mod, \"{}_train_{}\".format(single_model_mae[0][0], cd)), getattr(mod, \"{}_train_{}\".format(single_model_mae[1][0], cd))), axis=1)\n","  stack_final_x_test = np.concatenate((getattr(mod, \"{}_test_{}\".format(single_model_mae[0][0], cd)), getattr(mod, \"{}_test_{}\".format(single_model_mae[1][0], cd))), axis=1)\n","\n","  globals()[\"meta_model_{}_{}\".format(single_model_mae[2][0], cd)] = getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[2][0], cd))\n","\n","  getattr(mod, \"meta_model_{}_{}\".format(single_model_mae[2][0], cd)).fit(stack_final_x_train, y_train)\n","  globals()[\"stack_pred_{}_{}\".format(single_model_mae[2][0], cd)] = getattr(mod, \"meta_model_{}_{}\".format(single_model_mae[2][0], cd)).predict(stack_final_x_test)\n","  stacking_list[\"{}\".format(single_model_mae[2][0])] =  mean_absolute_error(y_test, getattr(mod, \"stack_pred_{}_{}\".format(single_model_mae[2][0], cd)))\n","\n","  # 두번째 경우\n","  globals()[\"{}_train_{}\".format(single_model_mae[0][0], cd)], globals()[\"{}_test_{}\".format(single_model_mae[0][0], cd)] = get_stacking_base_datasets(getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[0][0], cd)), x_train_n, y_train_n, x_test_n, 5)                                                                                               \n","  globals()[\"{}_train_{}\".format(single_model_mae[2][0], cd)], globals()[\"{}_test_{}\".format(single_model_mae[2][0], cd)] = get_stacking_base_datasets(getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[2][0], cd)), x_train_n, y_train_n, x_test_n, 5) \n","                                                                                                            \n","\n","  stack_final_x_train = np.concatenate((getattr(mod, \"{}_train_{}\".format(single_model_mae[0][0], cd)), getattr(mod, \"{}_train_{}\".format(single_model_mae[2][0], cd))), axis=1)\n","  stack_final_x_test = np.concatenate((getattr(mod, \"{}_test_{}\".format(single_model_mae[0][0], cd)), getattr(mod, \"{}_test_{}\".format(single_model_mae[2][0], cd))), axis=1)\n","\n","  globals()[\"meta_model_{}_{}\".format(single_model_mae[1][0], cd)] = getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[1][0], cd))\n","\n","  getattr(mod, \"meta_model_{}_{}\".format(single_model_mae[1][0], cd)).fit(stack_final_x_train, y_train)\n","  globals()[\"stack_pred_{}_{}\".format(single_model_mae[1][0], cd)] = getattr(mod, \"meta_model_{}_{}\".format(single_model_mae[1][0], cd)).predict(stack_final_x_test)\n","  stacking_list[\"{}\".format(single_model_mae[1][0])] =  mean_absolute_error(y_test, getattr(mod, \"stack_pred_{}_{}\".format(single_model_mae[1][0], cd)))\n","\n","\n","  # 세번째 경우\n","  globals()[\"{}_train_{}\".format(single_model_mae[1][0], cd)], globals()[\"{}_test_{}\".format(single_model_mae[1][0], cd)] = get_stacking_base_datasets(getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[1][0], cd)), x_train_n, y_train_n, x_test_n, 5)\n","                                                                                                            \n","  globals()[\"{}_train_{}\".format(single_model_mae[2][0], cd)], globals()[\"{}_test_{}\".format(single_model_mae[2][0], cd)] = get_stacking_base_datasets(getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[2][0], cd)), x_train_n, y_train_n, x_test_n, 5) \n","                                                                                                            \n","\n","  stack_final_x_train = np.concatenate((getattr(mod, \"{}_train_{}\".format(single_model_mae[1][0], cd)), getattr(mod, \"{}_train_{}\".format(single_model_mae[2][0], cd))), axis=1)\n","  stack_final_x_test = np.concatenate((getattr(mod, \"{}_test_{}\".format(single_model_mae[1][0], cd)), getattr(mod, \"{}_test_{}\".format(single_model_mae[2][0], cd))), axis=1)\n","\n","  globals()[\"meta_model_{}_{}\".format(single_model_mae[0][0], cd)] = getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[0][0], cd))\n","\n","  getattr(mod, \"meta_model_{}_{}\".format(single_model_mae[0][0], cd)).fit(stack_final_x_train, y_train)\n","  globals()[\"stack_pred_{}_{}\".format(single_model_mae[0][0], cd)] = getattr(mod, \"meta_model_{}_{}\".format(single_model_mae[0][0], cd)).predict(stack_final_x_test)\n","  stacking_list[\"{}\".format(single_model_mae[0][0])] =  mean_absolute_error(y_test, getattr(mod, \"stack_pred_{}_{}\".format(single_model_mae[0][0], cd)))\n","\n","  stacking_model_mae = sorted(stacking_list.items(), key = lambda item: item[1])\n","\n","  # 단일 모델과 stacking 모델의 MAE 값을 비교하여 작은 값으로 모델링 결과 반환\n","  a = single_model_mae[0][1]\n","  b = stacking_model_mae[0][1]\n","\n","  if a < b:\n","    print(\"Item 코드 {}의 최적 모델은 단일 모델 {} : (test MAE값) {}\".format(cd, single_model_mae[0][0], single_model_mae[0][1]))\n","    globals()[\"best_model_{}\".format(cd)]  = single_model_mae[0][0]\n","    globals()[\"test_mae_{}\".format(cd)] = single_model_mae[0][1]\n","    globals()[\"best_pred_{}\".format(cd)] = getattr(mod, \"single_pred_{}_{}\".format(single_model_mae[0][0], cd))\n","  else:\n","    print(\"Item 코드 {}의 최적 모델은 stacking meta 모델 {} : (test MAE값) {}\".format(cd, stacking_model_mae[0][0], stacking_model_mae[0][1]))\n","    globals()[\"best_model_{}\".format(cd)] = stacking_model_mae[0][0]\n","    globals()[\"test_mae_{}\".format(cd)] = stacking_model_mae[0][1]\n","    globals()[\"best_pred_{}\".format(cd)] = getattr(mod, \"stack_pred_{}_{}\".format(stacking_model_mae[0][0], cd))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LX9-RARbgAEv","executionInfo":{"status":"ok","timestamp":1635363275582,"user_tz":-540,"elapsed":1281804,"user":{"displayName":"‍김연재(학부학생/공과대학 산업공학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14786412166966495024"}},"outputId":"3c7f4b37-9cb6-4b1f-ef88-925af9ff4a1d"},"source":["# 단일 모델과 stacking 모델의 MAE 값을 비교하여 작은 값으로 모델링 결과 반환\n","for i in range(len(clusters)):\n","  print(\"Cluster \" + str(i))\n","  print(\"\")\n","  for cd in clusters[i]:\n","    get_optimal_model(str(cd))\n","  print(\"__________________________________________________________________________\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cluster 0\n","\n","Item 코드 5187227890의 최적 모델은 단일 모델 SVR : (test MAE값) 0.0393\n","Item 코드 655045121의 최적 모델은 단일 모델 GradientBoostingRegressor : (test MAE값) 2.5966\n","Item 코드 4624200932의 최적 모델은 stacking meta 모델 GradientBoostingRegressor : (test MAE값) 0.0009730483896049528\n","Item 코드 4610261043의 최적 모델은 단일 모델 SVR : (test MAE값) 0.1045\n","Item 코드 5326550997의 최적 모델은 단일 모델 SVR : (test MAE값) 0.3598\n","__________________________________________________________________________\n","Cluster 1\n","\n","Item 코드 5299553826의 최적 모델은 단일 모델 SVR : (test MAE값) 12.1343\n","Item 코드 8809641652409의 최적 모델은 단일 모델 SVR : (test MAE값) 10.7657\n","Item 코드 5519470982의 최적 모델은 단일 모델 GradientBoostingRegressor : (test MAE값) 41.4856\n","Item 코드 8809528221117의 최적 모델은 단일 모델 SVR : (test MAE값) 6.7478\n","Item 코드 8809528221414의 최적 모델은 단일 모델 SVR : (test MAE값) 8.0534\n","__________________________________________________________________________\n","Cluster 2\n","\n","Item 코드 4904383364의 최적 모델은 단일 모델 SVR : (test MAE값) 21.5987\n","Item 코드 4930635842의 최적 모델은 단일 모델 SVR : (test MAE값) 12.9045\n","Item 코드 5582257070의 최적 모델은 단일 모델 SVR : (test MAE값) 5.3653\n","Item 코드 5636360821의 최적 모델은 단일 모델 GradientBoostingRegressor : (test MAE값) 0.0112\n","Item 코드 5534486731의 최적 모델은 단일 모델 AdaBoostRegressor : (test MAE값) 6.799\n","__________________________________________________________________________\n","Cluster 3\n","\n","Item 코드 3681859516의 최적 모델은 단일 모델 SVR : (test MAE값) 426.1387\n","Item 코드 4929712168의 최적 모델은 stacking meta 모델 SVR : (test MAE값) 325.8\n","Item 코드 2055189125의 최적 모델은 stacking meta 모델 XGBRegressor : (test MAE값) 196.49999113082885\n","Item 코드 4207106945의 최적 모델은 stacking meta 모델 XGBRegressor : (test MAE값) 125.29998817443848\n","Item 코드 5157953843의 최적 모델은 stacking meta 모델 SVR : (test MAE값) 117.6\n","__________________________________________________________________________\n","Cluster 4\n","\n","Item 코드 2108751155의 최적 모델은 단일 모델 XGBRegressor : (test MAE값) 1.1535\n","Item 코드 5480996007의 최적 모델은 stacking meta 모델 AdaBoostRegressor : (test MAE값) 0.0\n","Item 코드 5240328576의 최적 모델은 단일 모델 XGBRegressor : (test MAE값) 1.4275\n","Item 코드 5002901812의 최적 모델은 단일 모델 GradientBoostingRegressor : (test MAE값) 1.775\n","Item 코드 5240330199의 최적 모델은 stacking meta 모델 GradientBoostingRegressor : (test MAE값) 0.06960683691271463\n","__________________________________________________________________________\n","Cluster 5\n","\n","Item 코드 232155349의 최적 모델은 단일 모델 SVR : (test MAE값) 9.9826\n","Item 코드 657383604의 최적 모델은 단일 모델 SVR : (test MAE값) 2.7992\n","Item 코드 5404706313의 최적 모델은 단일 모델 SVR : (test MAE값) 2.6659\n","Item 코드 414687646의 최적 모델은 단일 모델 SVR : (test MAE값) 0.9853\n","Item 코드 438888608의 최적 모델은 단일 모델 SVR : (test MAE값) 0.3565\n","__________________________________________________________________________\n","Cluster 6\n","\n","Item 코드 5569305322의 최적 모델은 단일 모델 GradientBoostingRegressor : (test MAE값) 0.0061\n","Item 코드 138632647의 최적 모델은 단일 모델 SVR : (test MAE값) 19.5992\n","Item 코드 5102599276의 최적 모델은 단일 모델 SVR : (test MAE값) 7.1901\n","Item 코드 5121269742의 최적 모델은 단일 모델 SVR : (test MAE값) 0.6686\n","Item 코드 5521930034의 최적 모델은 단일 모델 SVR : (test MAE값) 0.1041\n","__________________________________________________________________________\n","Cluster 7\n","\n","Item 코드 5638800672의 최적 모델은 stacking meta 모델 XGBRegressor : (test MAE값) 184.49999704360962\n","Item 코드 5002701828의 최적 모델은 단일 모델 SVR : (test MAE값) 130.3877\n","Item 코드 5497354651의 최적 모델은 단일 모델 SVR : (test MAE값) 8.0369\n","Item 코드 4730793965의 최적 모델은 stacking meta 모델 XGBRegressor : (test MAE값) 113.6999852180481\n","Item 코드 447405954의 최적 모델은 stacking meta 모델 XGBRegressor : (test MAE값) 113.09998521804809\n","__________________________________________________________________________\n","Cluster 8\n","\n","Item 코드 4802177320의 최적 모델은 단일 모델 SVR : (test MAE값) 7.9454\n","Item 코드 4824061918의 최적 모델은 단일 모델 SVR : (test MAE값) 25.0384\n","Item 코드 4802214590의 최적 모델은 단일 모델 SVR : (test MAE값) 6.2968\n","Item 코드 4658408144의 최적 모델은 stacking meta 모델 XGBRegressor : (test MAE값) 9.138249969482422\n","Item 코드 4733964360의 최적 모델은 단일 모델 GradientBoostingRegressor : (test MAE값) 8.419\n","__________________________________________________________________________\n","Cluster 9\n","\n","Item 코드 4609081354의 최적 모델은 단일 모델 GradientBoostingRegressor : (test MAE값) 1.4679\n","Item 코드 5109058837의 최적 모델은 단일 모델 GradientBoostingRegressor : (test MAE값) 0.2927\n","Item 코드 4288442391의 최적 모델은 단일 모델 SVR : (test MAE값) 4.5971\n","Item 코드 5279261934의 최적 모델은 단일 모델 SVR : (test MAE값) 3.932\n","Item 코드 5279251727의 최적 모델은 단일 모델 SVR : (test MAE값) 4.4634\n","__________________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"-kD86VNPIC8w"},"source":["# test dataset에 대한 예측값 \n","for i in range(len(clusters)):\n","  globals()['item_pred_df_{}'.format(str(i))] = pd.DataFrame()\n","  for cd in clusters[i]:\n","    getattr(mod, 'item_pred_df_{}'.format(str(i)))[str(cd)] = getattr(mod, \"best_pred_{}\".format(cd))\n","  globals()['item_pred_df_{}'.format(str(i))] = getattr(mod, 'item_pred_df_{}'.format(str(i))).transpose()\n","  getattr(mod, 'item_pred_df_{}'.format(str(i)))['Cluster'] = i"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PyEq3mAgUi7e"},"source":["item_pred_df = pd.concat([item_pred_df_0, item_pred_df_1, item_pred_df_2, item_pred_df_3, item_pred_df_4, item_pred_df_5, item_pred_df_6, item_pred_df_7, item_pred_df_8, item_pred_df_9])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fAOIzsGwxhU9"},"source":["item_pred_df.to_csv('/content/gdrive/Shareddrives/cj공모전/모델링/item_예측값.csv', encoding = 'utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zAPpNn-Hx179"},"source":[""],"execution_count":null,"outputs":[]}]}