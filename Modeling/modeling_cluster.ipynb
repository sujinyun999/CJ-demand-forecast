{"cells":[{"cell_type":"markdown","metadata":{},"source":["#### download package"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3041,"status":"ok","timestamp":1635432364107,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"X11eBgt8m_7G","outputId":"a7035809-2e6c-42fb-dcf9-f8f697440d08"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sktime in /usr/local/lib/python3.7/dist-packages (0.8.0)\n","Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.54.1)\n","Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.0.1)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from sktime) (0.37.0)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.19.5)\n","Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.13.0)\n","Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.1.5)\n","Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba>=0.53->sktime) (0.37.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.53->sktime) (57.4.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->sktime) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (3.0.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (1.0.1)\n","Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.1->sktime) (0.5.2)\n"]}],"source":["# download sktime package \n","!pip install sktime"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1635432364112,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"aqS4t0ovUqTb"},"outputs":[],"source":["# 필요한 패키지 import\n","import os\n","import sys\n","import warnings\n","import plotly\n","import numpy as np\n","import pandas as pd\n","import datetime\n","import tensorflow as tf\n","from tqdm import tqdm\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import KFold, train_test_split, TimeSeriesSplit, GridSearchCV, RandomizedSearchCV\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","from sklearn import preprocessing\n","from sklearn.preprocessing import RobustScaler, StandardScaler\n","from sktime.forecasting.model_selection import temporal_train_test_split\n","from sktime.utils.plotting import plot_series\n","from scipy.stats import reciprocal \n","\n","from xgboost import XGBRegressor\n","from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n","from sklearn.svm import SVR\n","import lightgbm as lgb\n","from lightgbm.sklearn import LGBMRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","\n","mpl.rcParams['figure.figsize'] = (8, 6)\n","mpl.rcParams['axes.grid'] = False\n","\n","warnings.filterwarnings('ignore')\n","pd.options.display.float_format = '{:.5f}'.format"]},{"cell_type":"markdown","metadata":{},"source":["## Model training"]},{"cell_type":"markdown","metadata":{},"source":["### making datasets"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1635432364118,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"6x6993ZHqvAf"},"outputs":[],"source":["cluster_df = ['0.0','1.0','2.0','3.0','4.0','5.0','6.0','7.0','8.0','9.0','10']"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1635432364119,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"YXYZvSEhoFNQ"},"outputs":[],"source":["# 학습에 필요한 train 및 test dataset 만드는 과정\n","def get_train_test_set(cluster):\n","  df = pd.read_pickle(\"cluster_\"+cluster+\".pkl\")\n","  train = df[df['BKG_DATE'] <= '2021-06-20']\n","  test = df[df['BKG_DATE'] > '2021-06-20']\n","  # 나머지 Scaling\n","  scaling_features = ['DAY_1', 'DAY_2', 'DAY_3', 'WEEK_AMT',\n","       '100이상 27307.5미만','27307.5이상 63200미만','63200이상 133375미만', '133375이상 290100미만',\n","       '290100이상 1170901미만','MEAN_PRICE', '강원', '경기', '경남', '경북', '광주',\n","       '대구', '대전', '부산', '서울', '세종', '울산', '인천', '전남', '전북', '제주', '충남', '충북']\n","\n","  scaler = StandardScaler()\n","  train.loc[:, scaling_features] = scaler.fit_transform(train[scaling_features])\n","  test.loc[:, scaling_features] = scaler.transform(test[scaling_features])\n","  train_x = train.drop(['ITEM_QTY','BKG_DATE'], axis=1)\n","  train_y = train['ITEM_QTY']\n","\n","  test_x = test.drop(['ITEM_QTY','BKG_DATE'], axis=1)\n","  test_y = test['ITEM_QTY']\n","  return train_x, train_y, test_x, test_y"]},{"cell_type":"markdown","metadata":{},"source":["### 모델 별 정의 및 파라미터 최적화"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1635432364120,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"fw_LCffCKoVE"},"outputs":[],"source":["# 모델별 학습 파라미터 정의\n","XGBRegressor_param = {'n_estimators' : [100], 'eta' : [0.01], 'min_child_weight' : np.arange(1, 8, 1), 'max_depth' : np.arange(3,9,1) , 'colsample_bytree' :np.arange(0.8, 1.0, 0.1), 'subsample' :np.arange(0.8, 1.0, 0.1)}\n","LGBMRegressor_param = {'max_depth' : range(3,15,3), 'min_child_weight': range(1,6,2), 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100], 'learning_rate':[0.1, 0.01], 'max_depth' : [6,8,10]}\n","SVR_param = {'kernel':['linear'], 'C':[1.0], 'epsilon':[0.1]}\n","GradientBoostingRegressor_param = {'n_estimators':[100], 'max_depth':np.arange(3,20,3)}\n","AdaBoostRegressor_param = {'n_estimators' : np.arange(25, 100, 25), 'loss': ['linear', 'square', 'exponential'], 'learning_rate': np.arange(0.1, 1)} "]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1635432364122,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"7_YiraP3Lp5F"},"outputs":[],"source":["# 모델별 정의\n","XGBRegressor_model = XGBRegressor(n_estimators = 100, objective = 'reg:squarederror')\n","LGBMRegressor_model = LGBMRegressor(n_estimators = 80)\n","SVR_model = SVR(kernel='linear', C=1.0, epsilon=0.1)\n","GradientBoostingRegressor_model = GradientBoostingRegressor(n_estimators=100, max_depth=3)\n","AdaBoostRegressor_model = AdaBoostRegressor(base_estimator=None)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1635432364123,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"xOwgwkfxOntj"},"outputs":[],"source":["# 단일 모델별 최적 파라미터로 모델링\n","def print_best_params(model, params, x_train, x_test, y_train, y_test, log=False):\n","\n","  tss = TimeSeriesSplit(n_splits=5)\n","  grid_model = GridSearchCV(model, cv = tss, param_grid=params, scoring='neg_mean_absolute_error')\n","  grid_model.fit(x_train, y_train)\n","  mae = -1 * grid_model.best_score_\n","  #print('{0} 최적 평균 mae값 : {1}, 최적 파라미터:{2}'.format(model.__class__.__name__, np.round(mae, 4), grid_model.best_params_))\n","\n","  best_model = grid_model.best_estimator_\n","  pred = best_model.predict(x_test)\n","\n","  if log:\n","    y_test = np.expm1(y_test)\n","    pred = np.expm1(pred)\n","  \n","  single_min_list = np.round(mean_absolute_error(y_test, pred), 4)\n","\n","  return best_model, single_min_list, pred"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1635432364131,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"UoKJha9-U3fw"},"outputs":[],"source":["# 단일 모델에서의 MAE 값이 가장 작은 세 개의 모델로 stacking, stacking model의 dataset 만드는 함수\n","def get_stacking_base_datasets(model, x_train_n, y_train_n, x_test_n, n_splits=5):\n","  # 지정된 n_folds 값으로 KFold 생성\n","  tss = TimeSeriesSplit(n_splits)\n","\n","  # 추후 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화\n","  train_fold_pred = np.zeros((x_train_n.shape[0], 1))\n","  test_pred = np.zeros((x_test_n.shape[0], n_splits))\n","  #print(model.__class__.__name__, ' model 시작')\n","\n","  for folder_counter, (train_index, valid_index) in enumerate(tss.split(x_train_n)):\n","    # 입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 세트 추출\n","    #print('\\t 폴드 세트: ', folder_counter, ' 시작')\n","    x_tr = x_train_n[train_index]\n","    y_tr = y_train_n[train_index]\n","    x_te = x_train_n[valid_index]\n","\n","    # 폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행\n","    model.fit(x_tr, y_tr)\n","    # 폴드 세트 내부에서 다시 만들어지 검증 데이터로 기반 모델 예측 후 데이터 저장\n","    train_fold_pred[valid_index, :] = model.predict(x_te).reshape(-1, 1)\n","    # 입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장\n","    test_pred[:, folder_counter] = model.predict(x_test_n)\n","\n","  # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성\n","  test_pred_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n","\n","  # train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n","  return train_fold_pred, test_pred_mean"]},{"cell_type":"markdown","metadata":{},"source":["### 모델 학습 과정\n","    - 단일 모델 학습 및 stacking 모델 학습\n","    - 모델별 성능 비교 후 최적의 모델 반환"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":48,"status":"ok","timestamp":1635432364147,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"betSsoZEFiV3"},"outputs":[],"source":["import sys\n","mod = sys.modules[__name__]"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1635432770911,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"IBoibHKPO26R"},"outputs":[],"source":["# 최적의 파라미터로 각각의 모델 학습\n","def get_optimal_model(cluster):\n","  x_train, y_train, x_test, y_test = get_train_test_set(cluster)\n","  x_train_n=x_train.values\n","  x_test_n=x_test.values\n","  y_train_n=y_train.values\n","  \n","  # 단일 모델별 성능 리스트\n","  single_min_list = dict()\n","  \n","  # 단일 모델 학습\n","  globals()[\"XGBRegressor_model_tuned_{}\".format(cluster)], single_min_list[\"XGBRegressor\"], globals()[\"single_pred_XGBRegressor_{}\".format(cluster)] = print_best_params(XGBRegressor_model, XGBRegressor_param, x_train, x_test, y_train, y_test)\n","  globals()[\"LGBMRegressor_model_tuned_{}\".format(cluster)], single_min_list[\"LGBMRegressor\"], globals()[\"single_pred_LGBMRegressor_{}\".format(cluster)] = print_best_params(LGBMRegressor_model, LGBMRegressor_param, x_train, x_test, y_train, y_test)\n","  globals()[\"SVR_model_tuned_{}\".format(cluster)], single_min_list[\"SVR\"], globals()[\"single_pred_SVR_{}\".format(cluster)] = print_best_params(SVR_model, SVR_param, x_train, x_test, y_train, y_test)\n","  globals()[\"GradientBoostingRegressor_model_tuned_{}\".format(cluster)], single_min_list[\"GradientBoostingRegressor\"], globals()[\"single_pred_GradientBoostingRegressor_{}\".format(cluster)] = print_best_params(GradientBoostingRegressor_model, GradientBoostingRegressor_param, x_train, x_test, y_train, y_test)\n","  globals()[\"AdaBoostRegressor_model_tuned_{}\".format(cluster)], single_min_list[\"AdaBoostRegressor\"], globals()[\"single_pred_AdaBoostRegressor_{}\".format(cluster)] = print_best_params(AdaBoostRegressor_model, AdaBoostRegressor_param, x_train, x_test, y_train, y_test)\n","\n","  single_model_mae = sorted(single_min_list.items(), key = lambda item: item[1])\n","  \n","  # Stacking 모델별 성능 리스트\n","  stacking_list = dict()\n","\n","# stacking model dataset 생성\n","  globals()[\"{}_train_{}\".format(single_model_mae[0][0], cluster)], globals()[\"{}_test_{}\".format(single_model_mae[0][0], cluster)] = get_stacking_base_datasets(getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[0][0], cluster)), x_train_n, y_train_n, x_test_n, 5)                                                                                                          \n","  globals()[\"{}_train_{}\".format(single_model_mae[1][0], cluster)], globals()[\"{}_test_{}\".format(single_model_mae[1][0], cluster)] = get_stacking_base_datasets(getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[1][0], cluster)), x_train_n, y_train_n, x_test_n, 5) \n","                                                                                                            \n","  # 첫번째 경우\n","  stack_final_x_train = np.concatenate((getattr(mod, \"{}_train_{}\".format(single_model_mae[0][0], cluster)), getattr(mod, \"{}_train_{}\".format(single_model_mae[1][0], cluster))), axis=1)\n","  stack_final_x_test = np.concatenate((getattr(mod, \"{}_test_{}\".format(single_model_mae[0][0], cluster)), getattr(mod, \"{}_test_{}\".format(single_model_mae[1][0], cluster))), axis=1)\n","\n","  globals()[\"meta_model_{}_{}\".format(single_model_mae[2][0], cluster)] = getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[2][0], cluster))\n","\n","  getattr(mod, \"meta_model_{}_{}\".format(single_model_mae[2][0], cluster)).fit(stack_final_x_train, y_train)\n","  globals()[\"stack_pred_{}_{}\".format(single_model_mae[2][0], cluster)] = getattr(mod, \"meta_model_{}_{}\".format(single_model_mae[2][0], cluster)).predict(stack_final_x_test)\n","  stacking_list[\"{}\".format(single_model_mae[2][0])] =  mean_absolute_error(y_test, getattr(mod, \"stack_pred_{}_{}\".format(single_model_mae[2][0], cluster)))\n","\n","  # 두번째 경우\n","  globals()[\"{}_train_{}\".format(single_model_mae[0][0], cluster)], globals()[\"{}_test_{}\".format(single_model_mae[0][0], cluster)] = get_stacking_base_datasets(getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[0][0], cluster)), x_train_n, y_train_n, x_test_n, 5)\n","                                                                                                            \n","  globals()[\"{}_train_{}\".format(single_model_mae[2][0], cluster)], globals()[\"{}_test_{}\".format(single_model_mae[2][0], cluster)] = get_stacking_base_datasets(getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[2][0], cluster)), x_train_n, y_train_n, x_test_n, 5) \n","                                                                                                            \n","\n","  stack_final_x_train = np.concatenate((getattr(mod, \"{}_train_{}\".format(single_model_mae[0][0], cluster)), getattr(mod, \"{}_train_{}\".format(single_model_mae[2][0], cluster))), axis=1)\n","  stack_final_x_test = np.concatenate((getattr(mod, \"{}_test_{}\".format(single_model_mae[0][0], cluster)), getattr(mod, \"{}_test_{}\".format(single_model_mae[2][0], cluster))), axis=1)\n","\n","  globals()[\"meta_model_{}_{}\".format(single_model_mae[1][0], cluster)] = getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[1][0], cluster))\n","\n","  getattr(mod, \"meta_model_{}_{}\".format(single_model_mae[1][0], cluster)).fit(stack_final_x_train, y_train)\n","  globals()[\"stack_pred_{}_{}\".format(single_model_mae[1][0], cluster)] = getattr(mod, \"meta_model_{}_{}\".format(single_model_mae[1][0], cluster)).predict(stack_final_x_test)\n","  stacking_list[\"{}\".format(single_model_mae[1][0])] =  mean_absolute_error(y_test, getattr(mod, \"stack_pred_{}_{}\".format(single_model_mae[1][0], cluster)))\n","\n","\n","  # 세번째 경우\n","  globals()[\"{}_train_{}\".format(single_model_mae[1][0], cluster)], globals()[\"{}_test_{}\".format(single_model_mae[1][0], cluster)] = get_stacking_base_datasets(getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[1][0], cluster)), x_train_n, y_train_n, x_test_n, 5)\n","                                                                                                            \n","  globals()[\"{}_train_{}\".format(single_model_mae[2][0], cluster)], globals()[\"{}_test_{}\".format(single_model_mae[2][0], cluster)] = get_stacking_base_datasets(getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[2][0], cluster)), x_train_n, y_train_n, x_test_n, 5) \n","                                                                                                            \n","\n","  stack_final_x_train = np.concatenate((getattr(mod, \"{}_train_{}\".format(single_model_mae[1][0], cluster)), getattr(mod, \"{}_train_{}\".format(single_model_mae[2][0], cluster))), axis=1)\n","  stack_final_x_test = np.concatenate((getattr(mod, \"{}_test_{}\".format(single_model_mae[1][0], cluster)), getattr(mod, \"{}_test_{}\".format(single_model_mae[2][0], cluster))), axis=1)\n","\n","  globals()[\"meta_model_{}_{}\".format(single_model_mae[0][0], cluster)] = getattr(mod, \"{}_model_tuned_{}\".format(single_model_mae[0][0], cluster))\n","\n","  getattr(mod, \"meta_model_{}_{}\".format(single_model_mae[0][0], cluster)).fit(stack_final_x_train, y_train)\n","  globals()[\"stack_pred_{}_{}\".format(single_model_mae[0][0], cluster)] = getattr(mod, \"meta_model_{}_{}\".format(single_model_mae[0][0], cluster)).predict(stack_final_x_test)\n","  stacking_list[\"{}\".format(single_model_mae[0][0])] =  mean_absolute_error(y_test, getattr(mod, \"stack_pred_{}_{}\".format(single_model_mae[0][0], cluster)))\n","\n","  stacking_model_mae = sorted(stacking_list.items(), key = lambda item: item[1])\n","\n","# 단일 모델과 stacking 모델의 MAE 값을 비교하여 작은 값으로 모델링 결과 반환\n","  a = single_model_mae[0][1]\n","  b = stacking_model_mae[0][1]\n","\n","  if a < b:\n","    print(\"클러스터 {}의 최적 모델은 단일 모델 {} : (test MAE값) {}\".format(cluster, single_model_mae[0][0], single_model_mae[0][1]))\n","    globals()[\"best_model_{}\".format(cluster)]  = single_model_mae[0][0]\n","    globals()[\"test_mae_{}\".format(cluster)] = single_model_mae[0][1]\n","    globals()[\"best_pred_{}\".format(cluster)] = getattr(mod, \"single_pred_{}_{}\".format(single_model_mae[0][0], cluster))\n","  else:\n","    print(\"클러스터 {}의 최적 모델은 stacking meta 모델 {} : (test MAE값) {}\".format(cluster, stacking_model_mae[0][0], stacking_model_mae[0][1]))\n","    globals()[\"best_model_{}\".format(cluster)] = stacking_model_mae[0][0]\n","    globals()[\"test_mae_{}\".format(cluster)] = stacking_model_mae[0][1]\n","    globals()[\"best_pred_{}\".format(cluster)] = getattr(mod, \"stack_pred_{}_{}\".format(stacking_model_mae[0][0], cluster))\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349417,"status":"ok","timestamp":1635433122744,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"LX9-RARbgAEv","outputId":"9b9a50fa-d93b-4206-d496-817a506e7930"},"outputs":[{"name":"stdout","output_type":"stream","text":["클러스터 0.0의 최적 모델은 단일 모델 SVR : (test MAE값) 0.0988\n","클러스터 1.0의 최적 모델은 단일 모델 SVR : (test MAE값) 0.0131\n","클러스터 2.0의 최적 모델은 단일 모델 SVR : (test MAE값) 0.0674\n","클러스터 3.0의 최적 모델은 단일 모델 SVR : (test MAE값) 79.5137\n","클러스터 4.0의 최적 모델은 단일 모델 SVR : (test MAE값) 0.0994\n","클러스터 5.0의 최적 모델은 단일 모델 SVR : (test MAE값) 0.073\n","클러스터 6.0의 최적 모델은 단일 모델 SVR : (test MAE값) 0.0495\n","클러스터 7.0의 최적 모델은 단일 모델 SVR : (test MAE값) 2.105\n","클러스터 8.0의 최적 모델은 단일 모델 SVR : (test MAE값) 0.075\n","클러스터 9.0의 최적 모델은 단일 모델 SVR : (test MAE값) 0.0894\n","클러스터 10의 최적 모델은 단일 모델 SVR : (test MAE값) 1.0727\n"]}],"source":["# 단일 모델과 stacking 모델의 MAE 값을 비교하여 작은 값으로 모델링 결과 반환\n","for cluster in cluster_df:\n","  get_optimal_model(cluster)"]},{"cell_type":"markdown","metadata":{},"source":["### 모델 학습 결과에 대한 예측"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1635433124180,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"lpk5wzBXjcfx"},"outputs":[],"source":["for cluster in cluster_df:\n","  x_train, y_train, x_test, y_test = get_train_test_set(cluster)\n","  globals()['pred_{}'.format(cluster)]= getattr(mod, \"stack_pred_{}_{}\".format(getattr(mod, \"best_model_{}\".format(cluster)), cluster))"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":559,"status":"ok","timestamp":1635433124733,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"nf4y3SqpoyVr"},"outputs":[],"source":["# test dataset에 대한 예측값 \n","cluster_pred_df = pd.DataFrame()\n","for cluster in cluster_df:\n","  cluster_pred_df[str(cluster)] = getattr(mod, 'best_pred_{}'.format(cluster))"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1635433124745,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"8srdGc-yxfor","outputId":"e8e766ad-de28-4742-b008-0caf75c269bf"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0.0</th>\n","      <th>1.0</th>\n","      <th>2.0</th>\n","      <th>3.0</th>\n","      <th>4.0</th>\n","      <th>5.0</th>\n","      <th>6.0</th>\n","      <th>7.0</th>\n","      <th>8.0</th>\n","      <th>9.0</th>\n","      <th>10</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>166.10037</td>\n","      <td>7594.97361</td>\n","      <td>1398.07139</td>\n","      <td>81.73906</td>\n","      <td>39.09945</td>\n","      <td>1111.06868</td>\n","      <td>5766.04072</td>\n","      <td>1810.56301</td>\n","      <td>9820.06514</td>\n","      <td>998.07880</td>\n","      <td>150.07448</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>169.09884</td>\n","      <td>6602.99179</td>\n","      <td>1055.07792</td>\n","      <td>100.49231</td>\n","      <td>48.09938</td>\n","      <td>990.07277</td>\n","      <td>5343.04579</td>\n","      <td>1922.28884</td>\n","      <td>9057.07069</td>\n","      <td>479.09027</td>\n","      <td>137.57177</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>182.09882</td>\n","      <td>6573.99264</td>\n","      <td>1007.08060</td>\n","      <td>86.76966</td>\n","      <td>50.09938</td>\n","      <td>974.07313</td>\n","      <td>4754.05148</td>\n","      <td>1299.35486</td>\n","      <td>8466.07533</td>\n","      <td>426.09133</td>\n","      <td>118.54490</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>135.09947</td>\n","      <td>6091.00082</td>\n","      <td>1051.07609</td>\n","      <td>91.28171</td>\n","      <td>38.09967</td>\n","      <td>992.07243</td>\n","      <td>4675.05255</td>\n","      <td>1642.15016</td>\n","      <td>7725.08070</td>\n","      <td>402.09101</td>\n","      <td>129.39766</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>115.09962</td>\n","      <td>6502.00657</td>\n","      <td>1089.07487</td>\n","      <td>109.77862</td>\n","      <td>109.09892</td>\n","      <td>622.08434</td>\n","      <td>5433.04435</td>\n","      <td>2096.67929</td>\n","      <td>6686.08861</td>\n","      <td>432.09104</td>\n","      <td>100.55541</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>106.09922</td>\n","      <td>4373.03115</td>\n","      <td>801.08279</td>\n","      <td>76.35226</td>\n","      <td>77.09923</td>\n","      <td>549.08619</td>\n","      <td>4139.05763</td>\n","      <td>2967.92142</td>\n","      <td>6725.08780</td>\n","      <td>256.09482</td>\n","      <td>112.60687</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>160.09669</td>\n","      <td>6513.99801</td>\n","      <td>1295.06579</td>\n","      <td>390.78756</td>\n","      <td>65.09967</td>\n","      <td>914.07348</td>\n","      <td>4664.05183</td>\n","      <td>2563.56521</td>\n","      <td>8532.07400</td>\n","      <td>491.08842</td>\n","      <td>170.05508</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>225.09772</td>\n","      <td>7195.98537</td>\n","      <td>4515.97876</td>\n","      <td>2621.65727</td>\n","      <td>51.09927</td>\n","      <td>1650.05270</td>\n","      <td>5164.04719</td>\n","      <td>2663.51074</td>\n","      <td>9958.06363</td>\n","      <td>498.08896</td>\n","      <td>156.88006</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>204.09837</td>\n","      <td>7654.98059</td>\n","      <td>1952.05728</td>\n","      <td>1794.95471</td>\n","      <td>50.09943</td>\n","      <td>1041.07240</td>\n","      <td>4896.05034</td>\n","      <td>1421.16306</td>\n","      <td>9073.07050</td>\n","      <td>525.08846</td>\n","      <td>206.01491</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>172.09910</td>\n","      <td>7384.98590</td>\n","      <td>1687.06589</td>\n","      <td>31959.89892</td>\n","      <td>42.09950</td>\n","      <td>979.07418</td>\n","      <td>4594.05268</td>\n","      <td>1373.43767</td>\n","      <td>8598.07386</td>\n","      <td>461.09059</td>\n","      <td>281.57189</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        0.0        1.0        2.0  ...        8.0       9.0        10\n","0 166.10037 7594.97361 1398.07139  ... 9820.06514 998.07880 150.07448\n","1 169.09884 6602.99179 1055.07792  ... 9057.07069 479.09027 137.57177\n","2 182.09882 6573.99264 1007.08060  ... 8466.07533 426.09133 118.54490\n","3 135.09947 6091.00082 1051.07609  ... 7725.08070 402.09101 129.39766\n","4 115.09962 6502.00657 1089.07487  ... 6686.08861 432.09104 100.55541\n","5 106.09922 4373.03115  801.08279  ... 6725.08780 256.09482 112.60687\n","6 160.09669 6513.99801 1295.06579  ... 8532.07400 491.08842 170.05508\n","7 225.09772 7195.98537 4515.97876  ... 9958.06363 498.08896 156.88006\n","8 204.09837 7654.98059 1952.05728  ... 9073.07050 525.08846 206.01491\n","9 172.09910 7384.98590 1687.06589  ... 8598.07386 461.09059 281.57189\n","\n","[10 rows x 11 columns]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["cluster_pred_df"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1635433124747,"user":{"displayName":"이유림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09001258585881898886"},"user_tz":-540},"id":"fAOIzsGwxhU9"},"outputs":[],"source":["cluster_pred_df.to_csv('./모델링/예측값/cluster_예측값.csv', encoding = 'utf-8', index = False)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Modeling_cluster_최종.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
